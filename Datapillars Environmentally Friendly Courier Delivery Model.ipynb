{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /home/baris/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /home/baris/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (1.26.4)\n",
            "Requirement already satisfied: datetime in /home/baris/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (5.5)\n",
            "Requirement already satisfied: psutil in /home/baris/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (6.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/baris/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/baris/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/baris/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: zope.interface in /home/baris/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from datetime) (7.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /home/baris/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /home/baris/miniconda3/envs/rapids-24.08/lib/python3.11/site-packages (from zope.interface->datetime) (72.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy datetime psutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import psutil\n",
        "import multiprocessing as mp\n",
        "import datetime\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ9qsa8h90UG",
        "outputId": "677b9b5a-5c0c-4df2-a96f-5dbb8824b582"
      },
      "outputs": [],
      "source": [
        "# I am using Windows Subsystem for Linux on a windows computer, therefore for data loading, I used /mnt. To load in a different environment, you need to specify paths. \n",
        "\n",
        "# Convert Windows paths to WSL paths\n",
        "all_data_path = '/mnt/c/Users/baris/Downloads/all_waybill_info_meituan.csv'\n",
        "courier_wave_path = '/mnt/c/Users/baris/Downloads/courier_wave_info_meituan.csv'\n",
        "dispatch_rider_path = '/mnt/c/Users/baris/Downloads/dispatch_rider_meituan.csv'\n",
        "cars_aggregated_path = '/mnt/c/Users/baris/Downloads/2021_Cars_Aggregated.csv'\n",
        "\n",
        "# Read CSV files into DataFrames\n",
        "all_data_df = pd.read_csv(all_data_path)\n",
        "courier_wave_df = pd.read_csv(courier_wave_path)\n",
        "dispatch_rider_df = pd.read_csv(dispatch_rider_path)\n",
        "cars_aggregated_df = pd.read_csv(cars_aggregated_path)\n",
        "\n",
        "# List of time-related columns in 'all_data_df' that need conversion\n",
        "time_columns = [\n",
        "    'estimate_arrived_time', 'dispatch_time', 'grab_time',\n",
        "    'fetch_time', 'arrive_time', 'order_push_time', 'platform_order_time', 'estimate_meal_prepare_time'\n",
        "]\n",
        "\n",
        "# Convert each time-related column from Unix timestamp to datetime\n",
        "for column in time_columns:\n",
        "    all_data_df[column] = pd.to_datetime(all_data_df[column], unit='s')\n",
        "\n",
        "# Convert the 'wave_start_time' and 'wave_end_time' columns from Unix timestamp to datetime\n",
        "courier_wave_df['wave_start_time'] = pd.to_datetime(courier_wave_df['wave_start_time'], unit='s')\n",
        "courier_wave_df['wave_end_time'] = pd.to_datetime(courier_wave_df['wave_end_time'], unit='s')\n",
        "\n",
        "# Convert the 'dispatch_time' column in 'dispatch_rider_df' from Unix timestamp to datetime\n",
        "dispatch_rider_df['dispatch_time'] = pd.to_datetime(dispatch_rider_df['dispatch_time'], unit='s')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Manufacturer', 'Fuel Type', 'Number of vehicles',\n",
            "       'OBFCM Fuel consumption (l/100 km)', 'WLTP Fuel consumption (l/100 km)',\n",
            "       'absolute gap Fuel consumption (l/100 km)',\n",
            "       'percentage gap Fuel consumption (%)', 'OBFCM CO2 emissions (g/km)',\n",
            "       'WLTP CO2 emissions (g/km)', 'absolute gap CO2 emissions (g/km)',\n",
            "       'percentage gap CO2 emissions (%)',\n",
            "       'OBFCM Fuel consumption weighted (l/100 km)',\n",
            "       'WLTP Fuel consumption weighted (l/100 km)',\n",
            "       'absolute gap Fuel consumption weighted (l/100 km)',\n",
            "       'percentage gap Fuel consumption weighted (%)',\n",
            "       'OBFCM CO2 emissions weighted (g/km)',\n",
            "       'WLTP CO2 emissions weighted (g/km)',\n",
            "       'absolute gap CO2 emissions weighted (g/km)',\n",
            "       'percentage gap CO2 emissions weighted (%)'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(cars_aggregated_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57b7cXGGX2vs",
        "outputId": "ae2cdbe6-a956-4c1f-d203-2537983d4e7d"
      },
      "outputs": [],
      "source": [
        "# List of time-related columns in 'all_data_df' that need conversion\n",
        "time_columns = [\n",
        "    'estimate_arrived_time', 'dispatch_time', 'grab_time',\n",
        "    'fetch_time', 'arrive_time', 'order_push_time', 'platform_order_time', 'estimate_meal_prepare_time'\n",
        "]\n",
        "\n",
        "# Reference date to compare against\n",
        "reference_date = pd.to_datetime('1970-01-01 00:00:00')\n",
        "\n",
        "# Drop rows where any time column has the reference date\n",
        "for column in time_columns:\n",
        "    all_data_df = all_data_df[all_data_df[column] != reference_date].reset_index(drop=True)\n",
        "\n",
        "# Ensure 'order_push_time' and 'arrive_time' are in datetime format\n",
        "all_data_df['order_push_time'] = pd.to_datetime(all_data_df['order_push_time'])\n",
        "all_data_df['arrive_time'] = pd.to_datetime(all_data_df['arrive_time'])\n",
        "\n",
        "# Extract the date from 'order_push_time' for grouping\n",
        "all_data_df['date'] = all_data_df['order_push_time'].dt.date\n",
        "\n",
        "# Group by 'courier_id' and 'date' to find min 'order_push_time' and max 'arrive_time'\n",
        "courier_availability = all_data_df.groupby(['courier_id', 'date']).agg(\n",
        "    min_order_push_time=('order_push_time', 'min'),\n",
        "    max_arrive_time=('arrive_time', 'max')\n",
        ").reset_index()\n",
        "\n",
        "# Separate date and time components\n",
        "courier_availability['min_order_push_hour'] = courier_availability['min_order_push_time'].dt.hour\n",
        "courier_availability['max_arrive_hour'] = courier_availability['max_arrive_time'].dt.hour\n",
        "\n",
        "# Drop the original datetime columns if only time is needed\n",
        "courier_availability.drop(columns=['min_order_push_time', 'max_arrive_time'], inplace=True)\n",
        "\n",
        "# Function to adjust time by adding or subtracting hours\n",
        "def adjust_and_extract_hour(hour, add_hours=0):\n",
        "    if pd.isna(hour):\n",
        "        return np.nan\n",
        "    adjusted_hour = hour + add_hours\n",
        "    return np.clip(adjusted_hour, 0, 23)  # Ensure valid hour between 0-23\n",
        "\n",
        "# Apply the adjustment:\n",
        "# Subtract 1 hour from 'min_order_push_hour'\n",
        "courier_availability['min_order_push_hour'] = courier_availability['min_order_push_hour'].apply(\n",
        "    lambda x: adjust_and_extract_hour(x, add_hours=-1)\n",
        ")\n",
        "\n",
        "# Add 1 hour to 'max_arrive_hour'\n",
        "courier_availability['max_arrive_hour'] = courier_availability['max_arrive_hour'].apply(\n",
        "    lambda x: adjust_and_extract_hour(x, add_hours=1)\n",
        ")\n",
        "\n",
        "# Calculate statistics for the specified columns\n",
        "statistics = courier_availability[['min_order_push_hour', 'max_arrive_hour']].describe()\n",
        "\n",
        "# Extracting specific statistics\n",
        "average_min_order_push_hour = statistics.loc['mean', 'min_order_push_hour']\n",
        "average_max_arrive_hour = statistics.loc['mean', 'max_arrive_hour']\n",
        "max_min_order_push_hour = statistics.loc['max', 'min_order_push_hour']\n",
        "max_max_arrive_hour = statistics.loc['max', 'max_arrive_hour']\n",
        "min_min_order_push_hour = statistics.loc['min', 'min_order_push_hour']\n",
        "min_max_arrive_hour = statistics.loc['min', 'max_arrive_hour']\n",
        "std_dev_min_order_push_hour = statistics.loc['std', 'min_order_push_hour']\n",
        "std_dev_max_arrive_hour = statistics.loc['std', 'max_arrive_hour']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define how many times to duplicate\n",
        "num_duplications = 4\n",
        "\n",
        "# Create an empty list to store the duplicated DataFrames\n",
        "duplicated_dfs = []\n",
        "\n",
        "# Get the max courier_id to start incrementing from\n",
        "max_courier_id = courier_availability['courier_id'].max()\n",
        "\n",
        "# Duplicate the DataFrame 'num_duplications' times\n",
        "for i in range(num_duplications):\n",
        "    # Make a copy of the original DataFrame\n",
        "    temp_df = courier_availability.copy()\n",
        "    \n",
        "    # Increment the 'courier_id' by (i+1) * max_courier_id to create new unique couriers\n",
        "    temp_df['courier_id'] = temp_df['courier_id'] + (i + 1) * (max_courier_id + 1)\n",
        "    \n",
        "    # Append the modified DataFrame to the list\n",
        "    duplicated_dfs.append(temp_df)\n",
        "\n",
        "# Concatenate the original DataFrame and the duplicated ones\n",
        "result_df = pd.concat([courier_availability] + duplicated_dfs, ignore_index=True)\n",
        "\n",
        "# Reset the index of the final DataFrame\n",
        "result_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming these are the statistics from your earlier calculations\n",
        "mean_min_order_push_hour = statistics.loc['mean', 'min_order_push_hour']\n",
        "std_dev_min_order_push_hour = statistics.loc['std', 'min_order_push_hour']\n",
        "mean_max_arrive_hour = statistics.loc['mean', 'max_arrive_hour']\n",
        "std_dev_max_arrive_hour = statistics.loc['std', 'max_arrive_hour']\n",
        "\n",
        "# Set min and max for valid hours (0-23)\n",
        "min_hour = 0\n",
        "max_hour = 23\n",
        "\n",
        "# Function to ensure max_arrive_hour > min_order_push_hour\n",
        "def generate_valid_hours():\n",
        "    while True:\n",
        "        # Generate 'min_order_push_hour' and 'max_arrive_hour' using a normal distribution\n",
        "        min_order_push_hour = int(np.random.normal(mean_min_order_push_hour, std_dev_min_order_push_hour))\n",
        "        max_arrive_hour = int(np.random.normal(mean_max_arrive_hour, std_dev_max_arrive_hour))\n",
        "        \n",
        "        # Clip values to ensure they are between 0 and 23\n",
        "        min_order_push_hour = np.clip(min_order_push_hour, min_hour, max_hour)\n",
        "        max_arrive_hour = np.clip(max_arrive_hour, min_hour, max_hour)\n",
        "        \n",
        "        # Ensure max_arrive_hour is greater than min_order_push_hour\n",
        "        if max_arrive_hour > min_order_push_hour:\n",
        "            return min_order_push_hour, max_arrive_hour\n",
        "\n",
        "# Apply the generation function for each row in the DataFrame\n",
        "for idx in range(len(result_df)):\n",
        "    result_df.at[idx, 'min_order_push_hour'], result_df.at[idx, 'max_arrive_hour'] = generate_valid_hours()\n",
        "    \n",
        "courier_availability=result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAxPA0oLSSwd",
        "outputId": "263f0df9-5495-4e9e-dcfb-fde86c670070"
      },
      "outputs": [],
      "source": [
        "# Assume courier_availability is already defined and loaded\n",
        "\n",
        "# Set a random seed for reproducibility (optional)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Determine the percentage of couriers to be assigned as bicycles\n",
        "percentage_bicycles = 0.33  # 33% of couriers\n",
        "\n",
        "# Get the list of all courier IDs\n",
        "all_couriers = courier_availability['courier_id'].unique()\n",
        "\n",
        "# Randomly select courier IDs to assign as bicycles\n",
        "num_bicycles = int(len(all_couriers) * percentage_bicycles)\n",
        "bicycle_couriers = np.random.choice(all_couriers, num_bicycles, replace=False)\n",
        "\n",
        "# Assign 'Bicycle' to the selected couriers and 'N/A' to the rest\n",
        "courier_availability['courier_type'] = courier_availability['courier_id'].apply(\n",
        "    lambda x: 'Bicycle' if x in bicycle_couriers else 'N/A'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDnNElnWTaO0",
        "outputId": "066a3484-80b4-44c6-a767-90c091a89269"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create 'car_type' column by merging 'Manufacturer' and 'Fuel Type'\n",
        "cars_aggregated_df['car_type'] = cars_aggregated_df['Manufacturer'] + ' ' + cars_aggregated_df['Fuel Type']\n",
        "\n",
        "# Define a function to assign car types based on the distribution\n",
        "def assign_car_types(courier_df, car_distribution):\n",
        "    # Filter out couriers with 'N/A' in 'courier_type'\n",
        "    na_couriers = courier_df[courier_df['courier_type'] == 'N/A']\n",
        "\n",
        "    if not na_couriers.empty:\n",
        "        # Create a list of car types and their distribution\n",
        "        car_types = car_distribution['car_type'].tolist()\n",
        "        probabilities = car_distribution['Number of vehicles'].tolist()\n",
        "\n",
        "        # Normalize probabilities\n",
        "        probabilities = np.array(probabilities) / sum(probabilities)\n",
        "\n",
        "        # Randomly assign car types to each 'N/A' courier based on the distribution\n",
        "        courier_df.loc[courier_df['courier_type'] == 'N/A', 'car_type'] = np.random.choice(car_types, size=len(na_couriers), p=probabilities)\n",
        "\n",
        "# Apply the function to assign car types to 'N/A' couriers\n",
        "assign_car_types(courier_availability, cars_aggregated_df)\n",
        "\n",
        "# Fill 'car_type' with 'Bicycle' where it is missing\n",
        "courier_availability['car_type'].fillna('Bicycle', inplace=True)\n",
        "\n",
        "# Determine the final vehicle type for each courier_id\n",
        "# Prioritize 'Bicycle' if it is the only option or if the 'car_type' is still missing\n",
        "courier_availability['courier_vehicle_type'] = courier_availability.groupby('courier_id')['car_type'].transform(lambda x: x.mode()[0])\n",
        "\n",
        "# Drop the original columns if no longer needed\n",
        "courier_availability.drop(columns=['courier_type', 'car_type'], inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GADlDcLRiCIm",
        "outputId": "07c1cf6a-d278-4851-ee1e-3b5a7aaaeb82"
      },
      "outputs": [],
      "source": [
        "# Create a mapping from car_type to WLTP CO2 emissions (g/km)\n",
        "co2_emissions_mapping = cars_aggregated_df[['car_type', 'WLTP CO2 emissions (g/km)']].drop_duplicates()\n",
        "co2_emissions_mapping.set_index('car_type', inplace=True)\n",
        "\n",
        "\n",
        "# Map CO2 emissions to the courier_availability DataFrame\n",
        "courier_availability['WLTP_CO2_emissions'] = courier_availability['courier_vehicle_type'].map(co2_emissions_mapping['WLTP CO2 emissions (g/km)'])\n",
        "\n",
        "# Set CO2 emissions to 0 for bicycles\n",
        "courier_availability.loc[courier_availability['courier_vehicle_type'] == 'Bicycle', 'WLTP_CO2_emissions'] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlClreamL_j3",
        "outputId": "5d3ab4bd-8c57-48a4-cf95-75dc9673903f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the columns relevant to order positions and platform order time\n",
        "order_position_columns = ['order_id', 'sender_lat', 'sender_lng', 'recipient_lat', 'recipient_lng', 'platform_order_time']\n",
        "\n",
        "# Extract these columns from all_data_df\n",
        "order_positions_df = all_data_df[order_position_columns]\n",
        "\n",
        "# Rename columns for clarity\n",
        "order_positions_df.rename(columns={\n",
        "    'sender_lat': 'order_start_lat',\n",
        "    'sender_lng': 'order_start_lng',\n",
        "    'recipient_lat': 'order_end_lat',\n",
        "    'recipient_lng': 'order_end_lng'\n",
        "}, inplace=True)\n",
        "\n",
        "# Convert platform_order_time to datetime format\n",
        "order_positions_df['platform_order_time'] = pd.to_datetime(order_positions_df['platform_order_time'])\n",
        "\n",
        "# Extract day, hour, and minute from platform_order_time\n",
        "order_positions_df['platform_order_day'] = order_positions_df['platform_order_time'].dt.date\n",
        "order_positions_df['platform_order_hour'] = order_positions_df['platform_order_time'].dt.hour\n",
        "order_positions_df['platform_order_minute'] = order_positions_df['platform_order_time'].dt.minute\n",
        "\n",
        "# Format hour and minute as HH:MM\n",
        "order_positions_df['platform_order_time_formatted'] = order_positions_df['platform_order_hour'].astype(str).str.zfill(2) + ':' + order_positions_df['platform_order_minute'].astype(str).str.zfill(2)\n",
        "\n",
        "# Drop the original platform_order_time if not needed\n",
        "order_positions_df.drop(columns=['platform_order_time','platform_order_hour','platform_order_minute'], inplace=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5AY-3hNJEkf",
        "outputId": "dedb990f-4b89-4a8d-e88a-3edaa3d0f3f4"
      },
      "outputs": [],
      "source": [
        "# Define latitude and longitude bounds and grid size from previous research\n",
        "latitude_min = 45820000\n",
        "latitude_max = 45980000\n",
        "longitude_min = 174400000\n",
        "longitude_max = 174650000\n",
        "grid_size = 1000\n",
        "\n",
        "# Create grid boundaries\n",
        "lat_bins = np.linspace(latitude_min, latitude_max, grid_size + 1)\n",
        "lng_bins = np.linspace(longitude_min, longitude_max, grid_size + 1)\n",
        "\n",
        "# Create an empty DataFrame to store grid cells\n",
        "zone_grid_df = pd.DataFrame(columns=['lat', 'lng', 'count'])\n",
        "\n",
        "# Step 1: Sort the DataFrame by latitude and longitude\n",
        "sorted_df = order_positions_df.sort_values(by=['order_start_lat', 'order_start_lng'])\n",
        "\n",
        "# Step 2: Split the sorted data into batches of 100\n",
        "batch_size = 100\n",
        "batches = [sorted_df[i:i + batch_size] for i in range(0, len(sorted_df), batch_size)]\n",
        "\n",
        "# Process each batch\n",
        "for batch in batches:\n",
        "    avg_lat = batch['order_start_lat'].mean()\n",
        "    avg_lng = batch['order_start_lng'].mean()\n",
        "\n",
        "    # Step 3: Determine which grid cell this batch belongs to\n",
        "    lat_idx = np.digitize(avg_lat, lat_bins) - 1\n",
        "    lng_idx = np.digitize(avg_lng, lng_bins) - 1\n",
        "\n",
        "    # Ensure lat_idx and lng_idx are within bounds\n",
        "    lat_idx = min(max(lat_idx, 0), grid_size - 1)\n",
        "    lng_idx = min(max(lng_idx, 0), grid_size - 1)\n",
        "\n",
        "    cell_lat = (lat_bins[lat_idx] + lat_bins[lat_idx + 1]) / 2\n",
        "    cell_lng = (lng_bins[lng_idx] + lng_bins[lng_idx + 1]) / 2\n",
        "\n",
        "    # Check if this grid cell already exists in the DataFrame\n",
        "    match = zone_grid_df[(zone_grid_df['lat'] == cell_lat) & (zone_grid_df['lng'] == cell_lng)]\n",
        "\n",
        "    if not match.empty:\n",
        "        # If the grid cell already exists, increment the count\n",
        "        zone_grid_df.loc[match.index, 'count'] += 1\n",
        "    else:\n",
        "        # If the grid cell doesn't exist, create a new row\n",
        "        new_row = pd.DataFrame({'lat': [cell_lat], 'lng': [cell_lng], 'count': [1]})\n",
        "        zone_grid_df = pd.concat([zone_grid_df, new_row], ignore_index=True)\n",
        "\n",
        "# Step 4: After processing all batches, assign zones based on density\n",
        "zone_grid_df = zone_grid_df.sort_values(by='count', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Top 100 most dense cells as \"Center\", next 200 as \"Nearby\", rest as \"Far\"\n",
        "zone_grid_df['zone'] = 'Far'\n",
        "zone_grid_df.loc[:200, 'zone'] = 'Center'\n",
        "zone_grid_df.loc[200:400, 'zone'] = 'Nearby'\n",
        "\n",
        "# Step 5: Save the zones in a different DataFrame\n",
        "city_zones_df = zone_grid_df[['lat', 'lng', 'zone']].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter only the \"Center\" zones from city_zones_df\n",
        "center_zones_df = city_zones_df[city_zones_df['zone'] == 'Center']\n",
        "\n",
        "# Function to generate a random position from the center zones\n",
        "def generate_random_position_from_center(center_zones_df):\n",
        "    # Randomly select a \"Center\" zone\n",
        "    random_zone = center_zones_df.sample(n=1).iloc[0]\n",
        "    \n",
        "    # Define latitude and longitude boundaries based on the grid size\n",
        "    lat_min = random_zone['lat'] - (grid_size / 2)\n",
        "    lat_max = random_zone['lat'] + (grid_size / 2)\n",
        "    lng_min = random_zone['lng'] - (grid_size / 2)\n",
        "    lng_max = random_zone['lng'] + (grid_size / 2)\n",
        "    \n",
        "    # Generate random latitude and longitude within the boundaries of the selected zone\n",
        "    random_lat = np.random.uniform(lat_min, lat_max)\n",
        "    random_lng = np.random.uniform(lng_min, lng_max)\n",
        "    \n",
        "    return random_lat, random_lng\n",
        "\n",
        "# Apply the random position generator to assign positions to couriers using only \"Center\" zones\n",
        "courier_availability[['courier_lat', 'courier_lng']] = courier_availability.apply(\n",
        "    lambda row: pd.Series(generate_random_position_from_center(center_zones_df)),\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1278/487078122.py:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  order_positions_df['order_time_unix'] = order_positions_df.apply(\n",
            "/tmp/ipykernel_1278/487078122.py:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[lat_column] = df[lat_column] / 1000000\n",
            "/tmp/ipykernel_1278/487078122.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[lng_column] = df[lng_column] / 1000000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Helper function to convert date and hour to Unix timestamp\n",
        "def to_unix_timestamp(date_str, hour):\n",
        "    dt_str = f\"{date_str} {hour}:00\"\n",
        "    dt_obj = datetime.strptime(dt_str, '%Y-%m-%d %H:%M')\n",
        "    return int(dt_obj.timestamp())\n",
        "\n",
        "def convert_to_unix_timestamps(courier_availability):\n",
        "    # Create Unix timestamp columns for min_order_push_hour and max_arrive_hour\n",
        "    courier_availability['min_order_push_unix'] = courier_availability.apply(\n",
        "        lambda row: to_unix_timestamp(row['date'], row['min_order_push_hour']), axis=1\n",
        "    )\n",
        "    \n",
        "    courier_availability['max_arrive_unix'] = courier_availability.apply(\n",
        "        lambda row: to_unix_timestamp(row['date'], row['max_arrive_hour']), axis=1\n",
        "    )\n",
        "\n",
        "    return courier_availability\n",
        "\n",
        "\n",
        "# Helper function to convert date and time to Unix timestamp\n",
        "def second_to_unix_timestamp(date_str, time_str=None):\n",
        "    if time_str:\n",
        "        combined_str = f\"{date_str} {time_str}\"\n",
        "        dt_obj = datetime.strptime(combined_str, '%Y-%m-%d %H:%M')\n",
        "    else:\n",
        "        dt_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
        "    return int(dt_obj.timestamp())\n",
        "\n",
        "# Convert order positions to Unix timestamps\n",
        "def convert_order_positions_to_unix(order_positions_df):\n",
        "    # Create Unix timestamp for the order time\n",
        "    order_positions_df['order_time_unix'] = order_positions_df.apply(\n",
        "        lambda row: second_to_unix_timestamp(row['platform_order_day'], row['platform_order_time_formatted']), axis=1\n",
        "    )\n",
        "    \n",
        "    return order_positions_df\n",
        "\n",
        "\n",
        "# Convert to Unix timestamps\n",
        "courier_availability = convert_to_unix_timestamps(courier_availability)\n",
        "order_positions_df = convert_order_positions_to_unix(order_positions_df)\n",
        "\n",
        "\n",
        "def convert_coordinates(df, lat_column, lng_column):\n",
        "    \"\"\"\n",
        "    Convert microcoordinates in the given dataframe to degrees and store them in new columns.\n",
        "    \"\"\"\n",
        "    df[lat_column] = df[lat_column] / 1000000\n",
        "    df[lng_column] = df[lng_column] / 1000000\n",
        "    return df\n",
        "\n",
        "# Convert courier_availability coordinates\n",
        "courier_availability = convert_coordinates(courier_availability, 'courier_lat', 'courier_lng')\n",
        "\n",
        "# Convert order_positions_df coordinates\n",
        "order_positions_df = convert_coordinates(order_positions_df, 'order_start_lat', 'order_start_lng')\n",
        "order_positions_df = convert_coordinates(order_positions_df, 'order_end_lat', 'order_end_lng')\n",
        "\n",
        "city_zones_df = convert_coordinates(city_zones_df,'lat','lng')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   order_id  order_start_lat  order_start_lng  order_end_lat  order_end_lng  \\\n",
            "0    493434        46.056274       174.951199      46.042858     174.928932   \n",
            "1    315761        45.872960       174.545650      45.880788     174.549996   \n",
            "2    153056        45.874288       174.647503      45.875341     174.633311   \n",
            "3    373814        45.880118       174.547076      45.871507     174.539996   \n",
            "4     95437        46.052237       174.943713      46.053611     174.946502   \n",
            "\n",
            "  platform_order_day platform_order_time_formatted  order_time_unix  \n",
            "0         2022-10-17                         03:06       1665968760  \n",
            "1         2022-10-17                         03:29       1665970140  \n",
            "2         2022-10-17                         03:29       1665970140  \n",
            "3         2022-10-17                         03:32       1665970320  \n",
            "4         2022-10-17                         04:02       1665972120  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Random Order Data from Order Positions\n",
        "random_order_positions_df = order_positions_df.sample(n=100, random_state=42)\n",
        "# Sort the DataFrame by the 'order_time_unix' column in ascending order\n",
        "random_order_positions_df = random_order_positions_df.sort_values(by='order_time_unix', ascending=True)\n",
        "\n",
        "# Reset the index of the sorted DataFrame\n",
        "random_order_positions_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(random_order_positions_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   courier_id        date  min_order_push_hour  max_arrive_hour  \\\n",
            "0           0  2022-10-17                    0                5   \n",
            "1           0  2022-10-18                    0               11   \n",
            "2           0  2022-10-20                    0                7   \n",
            "3           0  2022-10-23                    0                4   \n",
            "4           1  2022-10-16                    0               15   \n",
            "\n",
            "  courier_vehicle_type  WLTP_CO2_emissions  courier_lat  courier_lng  \\\n",
            "0              Bicycle                0.00    45.871452   174.596020   \n",
            "1              Bicycle                0.00    45.892346   174.568018   \n",
            "2              Bicycle                0.00    45.861161   174.572680   \n",
            "3              Bicycle                0.00    45.896002   174.552420   \n",
            "4    FIAT GROUP PETROL              133.18    45.884032   174.582646   \n",
            "\n",
            "   min_order_push_unix  max_arrive_unix  \n",
            "0           1665957600       1665975600  \n",
            "1           1666044000       1666083600  \n",
            "2           1666216800       1666242000  \n",
            "3           1666476000       1666490400  \n",
            "4           1665871200       1665925200  \n"
          ]
        }
      ],
      "source": [
        "print(courier_availability.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Before processing orders] Memory usage: 525.36 MB\n",
            "[Before processing orders] Memory usage: 525.42 MB\n",
            "[Before processing orders] Memory usage: 525.36 MB\n",
            "[Before processing orders] Memory usage: 525.36 MB\n",
            "[Before processing orders] Memory usage: 525.36 MB\n",
            "[Before processing orders] Memory usage: 525.36 MB\n",
            "[Before processing orders] Memory usage: 525.36 MB\n",
            "[Before processing orders] Memory usage: 525.36 MB\n",
            "[After processing orders] Memory usage: 528.46 MB\n",
            "[After processing orders] Memory usage: 528.46 MB\n",
            "[After processing orders] Memory usage: 528.46 MB\n",
            "[After processing orders] Memory usage: 528.46 MB\n",
            "[After processing orders] Memory usage: 528.46 MB\n",
            "[After processing orders] Memory usage: 528.46 MB\n",
            "[After processing orders] Memory usage: 528.46 MB\n",
            "[After processing orders] Memory usage: 528.46 MB\n",
            "   order_id  courier_id  total_delivery_time_hours  courier_available_at_unix  \\\n",
            "0    493434         NaN                        NaN                        NaN   \n",
            "1    315761     21851.0                   0.031218               1.665970e+09   \n",
            "2    153056      3535.0                   0.037544               1.665970e+09   \n",
            "3    373814     24286.0                   0.036938               1.665970e+09   \n",
            "4     95437         NaN                        NaN                        NaN   \n",
            "\n",
            "   road_distance_no_traffic_km  road_distance_with_traffic_km  \\\n",
            "0                          NaN                            NaN   \n",
            "1                     0.936538                       0.936538   \n",
            "2                     1.126310                       1.126310   \n",
            "3                     1.108149                       1.108149   \n",
            "4                          NaN                            NaN   \n",
            "\n",
            "             vehicle_type  environmental_impact_kg_CO2  order_start_time_unix  \\\n",
            "0                    None                          NaN             1665968760   \n",
            "1            DACIA DIESEL                   120.429449             1665970140   \n",
            "2  FORD WERKE GMBH PETROL                   145.327718             1665970140   \n",
            "3            DACIA PETROL                   140.136472             1665970320   \n",
            "4                    None                          NaN             1665972120   \n",
            "\n",
            "   order_end_time_unix                assignment_status  \n",
            "0                  NaN  there are no available couriers  \n",
            "1         1.665970e+09                   Order assigned  \n",
            "2         1.665970e+09                   Order assigned  \n",
            "3         1.665970e+09                   Order assigned  \n",
            "4                  NaN  there are no available couriers  \n"
          ]
        }
      ],
      "source": [
        "########## Fastest Vehicle Model #############\n",
        "\n",
        "# Function to print current memory usage\n",
        "def print_memory_usage(stage):\n",
        "    process = psutil.Process()\n",
        "    mem_info = process.memory_info()\n",
        "    print(f\"[{stage}] Memory usage: {mem_info.rss / (1024 * 1024):.2f} MB\")\n",
        "\n",
        "# Traffic delay factors based on zones\n",
        "TRAFFIC_FACTORS = {\n",
        "    'Center': 1.8,\n",
        "    'Nearby': 1.55,\n",
        "    'Far': 1.25\n",
        "}\n",
        "\n",
        "# Daytime hours (traffic delay applied during these hours)\n",
        "DAYTIME_START = 8  # 8:00 AM\n",
        "DAYTIME_END = 22  # 10:00 PM\n",
        "\n",
        "# Speed Definition for Cars and Bicycles\n",
        "car_speed = 30\n",
        "bicycle_speed = 15\n",
        "\n",
        "# Function to return traffic delay factor based on the zone\n",
        "def traffic_delay_factor(zone):\n",
        "    return TRAFFIC_FACTORS.get(zone, 1.0)\n",
        "\n",
        "# Function to find the nearest zone for given latitude and longitude\n",
        "def find_nearest_zone(lat, lng, city_zones_df):\n",
        "    city_zones_df['distance'] = ((city_zones_df['lat'] - lat) ** 2 + (city_zones_df['lng'] - lng) ** 2) ** 0.5\n",
        "    nearest_zone = city_zones_df.loc[city_zones_df['distance'].idxmin()]['zone']\n",
        "    return nearest_zone\n",
        "\n",
        "# Helper function to calculate delivery times using speed and distance\n",
        "def calculate_delivery_time(distance, speed_kmh):\n",
        "    return distance / speed_kmh\n",
        "\n",
        "# Haversine distance calculation function\n",
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "    import math\n",
        "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
        "    c = 2 * math.asin(math.sqrt(a))\n",
        "    r = 6371  # Radius of Earth in kilometers\n",
        "    return r * c\n",
        "\n",
        "# Environmental impact calculation function\n",
        "def calculate_environmental_impact(distance_km, co2_emissions_per_km):\n",
        "    if co2_emissions_per_km == 0:\n",
        "        return 0.0  # No emissions for zero-emission vehicles or bicycles\n",
        "    else:\n",
        "        return distance_km * co2_emissions_per_km\n",
        "\n",
        "# Function to calculate the traffic-adjusted distance for a segment based on its zone\n",
        "def apply_segment_traffic_factor(lat1, lng1, lat2, lng2, vehicle_type, city_zones_df, order_time_unix):\n",
        "    order_time = datetime.utcfromtimestamp(order_time_unix)\n",
        "    order_hour = order_time.hour\n",
        "\n",
        "    if order_hour < DAYTIME_START or order_hour >= DAYTIME_END:\n",
        "        return haversine_distance(lat1, lng1, lat2, lng2)\n",
        "    \n",
        "    distance = haversine_distance(lat1, lng1, lat2, lng2)\n",
        "\n",
        "    if vehicle_type != 'Bicycle':\n",
        "        zone_1 = find_nearest_zone(lat1, lng1, city_zones_df)\n",
        "        zone_2 = find_nearest_zone(lat2, lng2, city_zones_df)\n",
        "        traffic_factor_1 = traffic_delay_factor(zone_1)\n",
        "        traffic_factor_2 = traffic_delay_factor(zone_2)\n",
        "        segment_traffic_factor = (traffic_factor_1 + traffic_factor_2) / 2\n",
        "        distance *= segment_traffic_factor\n",
        "    \n",
        "    return distance\n",
        "\n",
        "# Function to process orders for each day in a process (for multiprocessing)\n",
        "def process_orders_for_day(order_positions_day, courier_availability, city_zones_df):\n",
        "    result_df = assign_couriers_to_orders(order_positions_day, courier_availability, city_zones_df)\n",
        "    return result_df\n",
        "\n",
        "# Main courier selection function\n",
        "def assign_couriers_to_orders(order_positions_df, courier_availability, city_zones_df):\n",
        "    results = []\n",
        "    courier_availabilities = {}\n",
        "\n",
        "    # Memory tracking before processing orders\n",
        "    print_memory_usage(\"Before processing orders\")\n",
        "\n",
        "    for _, order in order_positions_df.iterrows():\n",
        "        order_time_unix = order['order_time_unix']  # This is the order start time\n",
        "\n",
        "        available_couriers = courier_availability[\n",
        "            (courier_availability['min_order_push_unix'] <= order_time_unix) &\n",
        "            (courier_availability['max_arrive_unix'] >= order_time_unix)\n",
        "        ]\n",
        "        \n",
        "        # Initialize variables for the fastest courier\n",
        "        fastest_courier = None\n",
        "        min_total_time = float('inf')\n",
        "        best_total_road_distance_with_traffic = float('inf')\n",
        "        best_total_road_distance_no_traffic = float('inf')\n",
        "        best_vehicle_type = None\n",
        "        best_environmental_impact = float('inf')\n",
        "        \n",
        "        order_start_lat = order['order_start_lat']\n",
        "        order_start_lng = order['order_start_lng']\n",
        "        order_end_lat = order['order_end_lat']\n",
        "        order_end_lng = order['order_end_lng']\n",
        "        \n",
        "        available_couriers = available_couriers.copy()\n",
        "\n",
        "        # Calculate the distance to the order for each courier\n",
        "        available_couriers.loc[:, 'distance_to_order'] = available_couriers.apply(\n",
        "            lambda courier: haversine_distance(\n",
        "                courier['courier_lat'], courier['courier_lng'], \n",
        "                order_start_lat, order_start_lng\n",
        "            ), axis=1\n",
        "        )\n",
        "\n",
        "        # Filter couriers within 10 km\n",
        "        available_couriers_in_range = available_couriers[available_couriers['distance_to_order'] <= 10]\n",
        "        # If no couriers are available within 10 km, mark the order as unassigned\n",
        "        if available_couriers_in_range.empty:\n",
        "            results.append({\n",
        "                'order_id': order['order_id'],\n",
        "                'courier_id': None,\n",
        "                'total_delivery_time_hours': None,\n",
        "                'courier_available_at_unix': None,\n",
        "                'road_distance_no_traffic_km': None,\n",
        "                'road_distance_with_traffic_km': None,\n",
        "                'vehicle_type': None,\n",
        "                'environmental_impact_kg_CO2': None,\n",
        "                'order_start_time_unix': order_time_unix,  # Add order start time\n",
        "                'order_end_time_unix': None,  # No end time since no courier is assigned\n",
        "                'assignment_status': 'there are no available couriers'\n",
        "            })\n",
        "            continue  # Skip to the next order\n",
        "\n",
        "        # If couriers are available in range, proceed with the existing logic\n",
        "        for _, courier in available_couriers_in_range.iterrows():\n",
        "            courier_id = courier['courier_id']\n",
        "\n",
        "            if courier_id in courier_availabilities:\n",
        "                courier_start_lat = courier_availabilities[courier_id]['lat']\n",
        "                courier_start_lng = courier_availabilities[courier_id]['lng']\n",
        "                courier_available_at = courier_availabilities[courier_id]['available_at']\n",
        "            else:\n",
        "                courier_start_lat = courier['courier_lat']\n",
        "                courier_start_lng = courier['courier_lng']\n",
        "                courier_available_at = order_time_unix\n",
        "\n",
        "            if courier_available_at > order_time_unix:\n",
        "                continue\n",
        "\n",
        "            vehicle_type = courier['courier_vehicle_type']\n",
        "            co2_emissions_per_km = courier['WLTP_CO2_emissions']\n",
        "\n",
        "            # Calculate the distances without traffic (base road distance)\n",
        "            courier_to_order_dist_no_traffic = haversine_distance(\n",
        "                courier_start_lat, courier_start_lng, \n",
        "                order_start_lat, order_start_lng\n",
        "            )\n",
        "            \n",
        "            order_to_delivery_dist_no_traffic = haversine_distance(\n",
        "                order_start_lat, order_start_lng, \n",
        "                order_end_lat, order_end_lng\n",
        "            )\n",
        "\n",
        "            total_road_distance_no_traffic = courier_to_order_dist_no_traffic + order_to_delivery_dist_no_traffic\n",
        "\n",
        "            # Calculate the distances with traffic delay for each segment\n",
        "            courier_to_order_dist_with_traffic = apply_segment_traffic_factor(\n",
        "                courier_start_lat, courier_start_lng, \n",
        "                order_start_lat, order_start_lng, \n",
        "                vehicle_type, city_zones_df, order_time_unix\n",
        "            )\n",
        "            \n",
        "            order_to_delivery_dist_with_traffic = apply_segment_traffic_factor(\n",
        "                order_start_lat, order_start_lng, \n",
        "                order_end_lat, order_end_lng, \n",
        "                vehicle_type, city_zones_df, order_time_unix\n",
        "            )\n",
        "\n",
        "            total_road_distance_with_traffic = courier_to_order_dist_with_traffic + order_to_delivery_dist_with_traffic\n",
        "\n",
        "            if vehicle_type == 'Bicycle':\n",
        "                speed_kmh = bicycle_speed\n",
        "            else:\n",
        "                speed_kmh = car_speed\n",
        "\n",
        "            courier_to_order_time = calculate_delivery_time(courier_to_order_dist_with_traffic, speed_kmh)\n",
        "            order_to_delivery_time = calculate_delivery_time(order_to_delivery_dist_with_traffic, speed_kmh)\n",
        "            total_delivery_time = courier_to_order_time + order_to_delivery_time\n",
        "\n",
        "            # Calculate the environmental impact for the trip\n",
        "            total_environmental_impact = calculate_environmental_impact(\n",
        "                total_road_distance_no_traffic, co2_emissions_per_km\n",
        "            )\n",
        "\n",
        "            if total_delivery_time < min_total_time:\n",
        "                min_total_time = total_delivery_time\n",
        "                fastest_courier = courier\n",
        "                best_total_road_distance_with_traffic = total_road_distance_with_traffic\n",
        "                best_total_road_distance_no_traffic = total_road_distance_no_traffic\n",
        "                best_vehicle_type = vehicle_type\n",
        "                best_environmental_impact = total_environmental_impact\n",
        "\n",
        "        # If a courier is assigned, update their availability and log the result\n",
        "        if fastest_courier is not None and not fastest_courier.empty:\n",
        "            courier_id = fastest_courier['courier_id']\n",
        "            order_end_time_unix = order_time_unix + int(min_total_time * 3600)  # Calculating order end time\n",
        "\n",
        "            courier_availabilities[courier_id] = {\n",
        "                'available_at': order_end_time_unix,\n",
        "                'lat': order['order_end_lat'],\n",
        "                'lng': order['order_end_lng']\n",
        "            }\n",
        "\n",
        "            results.append({\n",
        "                'order_id': order['order_id'],\n",
        "                'courier_id': courier_id,\n",
        "                'total_delivery_time_hours': min_total_time,\n",
        "                'courier_available_at_unix': order_end_time_unix,\n",
        "                'road_distance_no_traffic_km': best_total_road_distance_no_traffic,\n",
        "                'road_distance_with_traffic_km': best_total_road_distance_with_traffic,\n",
        "                'vehicle_type': best_vehicle_type,\n",
        "                'environmental_impact_kg_CO2': best_environmental_impact,\n",
        "                'order_start_time_unix': order_time_unix,  # Add order start time\n",
        "                'order_end_time_unix': order_end_time_unix,  # Add order end time\n",
        "                'assignment_status': 'Order assigned'\n",
        "            })\n",
        "\n",
        "    print_memory_usage(\"After processing orders\")\n",
        "\n",
        "    fastest_car_results_df = pd.DataFrame(results)\n",
        "    return fastest_car_results_df\n",
        "\n",
        "# Main function to run processes for each day\n",
        "def run_model_with_multiprocessing(order_positions_df, courier_availability, city_zones_df):\n",
        "    # Split the order_positions_df by day\n",
        "    days = order_positions_df['platform_order_day'].unique()\n",
        "    pool = mp.Pool(mp.cpu_count())  # Create a pool of workers\n",
        "    results = pool.starmap(process_orders_for_day, [(order_positions_df[order_positions_df['platform_order_day'] == day], courier_availability, city_zones_df) for day in days])\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "\n",
        "    # Combine results\n",
        "    fastest_car_results_df = pd.concat(results, ignore_index=True)\n",
        "    return fastest_car_results_df\n",
        "\n",
        "# Example usage with multiprocessing\n",
        "fastest_car_results_df = run_model_with_multiprocessing(random_order_positions_df, courier_availability, city_zones_df)\n",
        "print(fastest_car_results_df.head())\n",
        "\n",
        "# Save the random_order_positions_df as CSV to a Windows directory\n",
        "#windows_path = '/mnt/c/Users/baris/Downloads/fastest_vehicle_model_results.csv'\n",
        "#results_df.to_csv(windows_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Before processing orders] Memory usage: 559.54 MB\n",
            "[Before processing orders] Memory usage: 559.54 MB\n",
            "[Before processing orders] Memory usage: 559.54 MB\n",
            "[Before processing orders] Memory usage: 559.54 MB\n",
            "[Before processing orders] Memory usage: 559.54 MB\n",
            "[Before processing orders] Memory usage: 559.54 MB\n",
            "[Before processing orders] Memory usage: 559.54 MB\n",
            "[Before processing orders] Memory usage: 559.54 MB\n",
            "[After processing orders] Memory usage: 562.15 MB\n",
            "[After processing orders] Memory usage: 562.15 MB\n",
            "[After processing orders] Memory usage: 562.15 MB\n",
            "[After processing orders] Memory usage: 562.15 MB\n",
            "[After processing orders] Memory usage: 562.15 MB\n",
            "[After processing orders] Memory usage: 562.15 MB\n",
            "[After processing orders] Memory usage: 562.15 MB\n",
            "[After processing orders] Memory usage: 562.15 MB\n",
            "   order_id  courier_id  total_delivery_time_hours  courier_available_at_unix  \\\n",
            "0    493434         NaN                        NaN                        NaN   \n",
            "1    315761      7966.0                   0.062508               1.665970e+09   \n",
            "2    153056     15326.0                   0.074919               1.665970e+09   \n",
            "3    373814     13982.0                   0.074463               1.665971e+09   \n",
            "4     95437         NaN                        NaN                        NaN   \n",
            "\n",
            "   road_distance_no_traffic_km  road_distance_with_traffic_km vehicle_type  \\\n",
            "0                          NaN                            NaN         None   \n",
            "1                     0.937627                       0.937627      Bicycle   \n",
            "2                     1.123784                       1.123784      Bicycle   \n",
            "3                     1.116944                       1.116944      Bicycle   \n",
            "4                          NaN                            NaN         None   \n",
            "\n",
            "   environmental_impact_kg_CO2  order_start_time_unix  order_end_time_unix  \\\n",
            "0                          NaN             1665968760                  NaN   \n",
            "1                          0.0             1665970140         1.665970e+09   \n",
            "2                          0.0             1665970140         1.665970e+09   \n",
            "3                          0.0             1665970320         1.665971e+09   \n",
            "4                          NaN             1665972120                  NaN   \n",
            "\n",
            "                    Order assigned  \n",
            "0  There are no available couriers  \n",
            "1            Successfully assigned  \n",
            "2            Successfully assigned  \n",
            "3            Successfully assigned  \n",
            "4  There are no available couriers  \n"
          ]
        }
      ],
      "source": [
        "########## DataPillars Environmentally Friendly Courier Delivery Model #############\n",
        "\n",
        "# Function to print current memory usage\n",
        "def print_memory_usage(stage):\n",
        "    process = psutil.Process()\n",
        "    mem_info = process.memory_info()\n",
        "    print(f\"[{stage}] Memory usage: {mem_info.rss / (1024 * 1024):.2f} MB\")\n",
        "\n",
        "# Traffic delay factors based on zones\n",
        "TRAFFIC_FACTORS = {\n",
        "    'Center': 1.8,\n",
        "    'Nearby': 1.55,\n",
        "    'Far': 1.25\n",
        "}\n",
        "\n",
        "# Daytime hours (traffic delay applied during these hours)\n",
        "DAYTIME_START = 8  # 8:00 AM\n",
        "DAYTIME_END = 22  # 10:00 PM\n",
        "\n",
        "# Time thresholds (minutes to hours)\n",
        "BICYCLE_TIME_THRESHOLD = 6 / 60  # 6 minutes in hours\n",
        "ENVIRONMENTAL_TIME_THRESHOLD = 3 / 60  # 3 minutes in hours\n",
        "\n",
        "# Speed Definition for Cars and Bicycles\n",
        "car_speed = 30\n",
        "bicycle_speed = 15\n",
        "\n",
        "# Function to return traffic delay factor based on the zone\n",
        "def traffic_delay_factor(zone):\n",
        "    return TRAFFIC_FACTORS.get(zone, 1.0)\n",
        "\n",
        "# Function to find the nearest zone for given latitude and longitude\n",
        "def find_nearest_zone(lat, lng, city_zones_df):\n",
        "    city_zones_df['distance'] = ((city_zones_df['lat'] - lat) ** 2 + (city_zones_df['lng'] - lng) ** 2) ** 0.5\n",
        "    nearest_zone = city_zones_df.loc[city_zones_df['distance'].idxmin()]['zone']\n",
        "    return nearest_zone\n",
        "\n",
        "# Helper function to calculate delivery times using speed and distance\n",
        "def calculate_delivery_time(distance, speed_kmh):\n",
        "    return distance / speed_kmh\n",
        "\n",
        "# Haversine distance calculation function\n",
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
        "    c = 2 * math.asin(math.sqrt(a))\n",
        "    r = 6371  # Radius of Earth in kilometers\n",
        "    return r * c\n",
        "\n",
        "# Environmental impact calculation function\n",
        "def calculate_environmental_impact(distance_km, co2_emissions_per_km):\n",
        "    if co2_emissions_per_km == 0:\n",
        "        return 0.0  # No emissions for zero-emission vehicles or bicycles\n",
        "    else:\n",
        "        return distance_km * co2_emissions_per_km\n",
        "\n",
        "# Function to calculate the traffic-adjusted distance for a segment based on its zone\n",
        "def apply_segment_traffic_factor(lat1, lng1, lat2, lng2, vehicle_type, city_zones_df, order_time_unix):\n",
        "    order_time = datetime.utcfromtimestamp(order_time_unix)\n",
        "    order_hour = order_time.hour\n",
        "\n",
        "    if order_hour < DAYTIME_START or order_hour >= DAYTIME_END:\n",
        "        return haversine_distance(lat1, lng1, lat2, lng2)\n",
        "    \n",
        "    distance = haversine_distance(lat1, lng1, lat2, lng2)\n",
        "\n",
        "    if vehicle_type != 'Bicycle':\n",
        "        zone_1 = find_nearest_zone(lat1, lng1, city_zones_df)\n",
        "        zone_2 = find_nearest_zone(lat2, lng2, city_zones_df)\n",
        "        traffic_factor_1 = traffic_delay_factor(zone_1)\n",
        "        traffic_factor_2 = traffic_delay_factor(zone_2)\n",
        "        segment_traffic_factor = (traffic_factor_1 + traffic_factor_2) / 2\n",
        "        distance *= segment_traffic_factor\n",
        "    \n",
        "    return distance\n",
        "\n",
        "# Function to process orders for each day in a process (for multiprocessing)\n",
        "def process_orders_for_day(order_positions_day, courier_availability, city_zones_df):\n",
        "    result_df = assign_couriers_to_orders(order_positions_day, courier_availability, city_zones_df)\n",
        "    return result_df\n",
        "\n",
        "def assign_couriers_to_orders(order_positions_df, courier_availability, city_zones_df):\n",
        "    results = []\n",
        "    courier_availabilities = {}\n",
        "\n",
        "    # Memory tracking before processing orders\n",
        "    print_memory_usage(\"Before processing orders\")\n",
        "\n",
        "    for _, order in order_positions_df.iterrows():\n",
        "        order_time_unix = order['order_time_unix']  # This will be the order start time (order_start_time_unix)\n",
        "\n",
        "        available_couriers = courier_availability[\n",
        "            (courier_availability['min_order_push_unix'] <= order_time_unix) &\n",
        "            (courier_availability['max_arrive_unix'] >= order_time_unix)\n",
        "        ]\n",
        "\n",
        "        # Check for couriers within a 10 km range\n",
        "        order_start_lat = order['order_start_lat']\n",
        "        order_start_lng = order['order_start_lng']\n",
        "        available_couriers = available_couriers.copy()\n",
        "\n",
        "        # Filter couriers within a 10 km range using .loc\n",
        "        couriers_in_range = available_couriers[\n",
        "            available_couriers.apply(\n",
        "                lambda x: haversine_distance(x['courier_lat'], x['courier_lng'], order_start_lat, order_start_lng) <= 10, \n",
        "                axis=1\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        if couriers_in_range.empty:\n",
        "            # No available couriers in range\n",
        "            results.append({\n",
        "                'order_id': order['order_id'],\n",
        "                'courier_id': None,\n",
        "                'total_delivery_time_hours': None,\n",
        "                'courier_available_at_unix': None,\n",
        "                'road_distance_no_traffic_km': None,\n",
        "                'road_distance_with_traffic_km': None,\n",
        "                'vehicle_type': None,\n",
        "                'environmental_impact_kg_CO2': None,\n",
        "                'order_start_time_unix': order_time_unix,\n",
        "                'order_end_time_unix': None,\n",
        "                'Order assigned': \"There are no available couriers\"\n",
        "            })\n",
        "            continue  # Move to the next order\n",
        "\n",
        "        fastest_courier = None\n",
        "        min_total_time = float('inf')\n",
        "        fastest_bicycle_courier = None\n",
        "        min_bicycle_time = float('inf')\n",
        "        least_environmental_impact_courier = None\n",
        "        min_environmental_impact_time = float('inf')\n",
        "        min_environmental_impact_value = float('inf')\n",
        "\n",
        "        # Step 1: Find the fastest courier (assign them first)\n",
        "        for _, courier in couriers_in_range.iterrows():\n",
        "            courier_id = courier['courier_id']\n",
        "\n",
        "            if courier_id in courier_availabilities:\n",
        "                courier_start_lat = courier_availabilities[courier_id]['lat']\n",
        "                courier_start_lng = courier_availabilities[courier_id]['lng']\n",
        "                courier_available_at = courier_availabilities[courier_id]['available_at']\n",
        "            else:\n",
        "                courier_start_lat = courier['courier_lat']\n",
        "                courier_start_lng = courier['courier_lng']\n",
        "                courier_available_at = order_time_unix\n",
        "\n",
        "            if courier_available_at > order_time_unix:\n",
        "                continue\n",
        "\n",
        "            order_end_lat = order['order_end_lat']\n",
        "            order_end_lng = order['order_end_lng']\n",
        "            vehicle_type = courier['courier_vehicle_type']\n",
        "            co2_emissions_per_km = courier['WLTP_CO2_emissions']\n",
        "\n",
        "            # Calculate the distances (no traffic)\n",
        "            courier_to_order_dist_no_traffic = haversine_distance(\n",
        "                courier_start_lat, courier_start_lng, \n",
        "                order_start_lat, order_start_lng\n",
        "            )\n",
        "            \n",
        "            order_to_delivery_dist_no_traffic = haversine_distance(\n",
        "                order_start_lat, order_start_lng, \n",
        "                order_end_lat, order_end_lng\n",
        "            )\n",
        "\n",
        "            total_road_distance_no_traffic = courier_to_order_dist_no_traffic + order_to_delivery_dist_no_traffic\n",
        "\n",
        "            # Calculate traffic-adjusted distances\n",
        "            courier_to_order_dist_with_traffic = apply_segment_traffic_factor(\n",
        "                courier_start_lat, courier_start_lng, \n",
        "                order_start_lat, order_start_lng, \n",
        "                vehicle_type, city_zones_df, order_time_unix\n",
        "            )\n",
        "            \n",
        "            order_to_delivery_dist_with_traffic = apply_segment_traffic_factor(\n",
        "                order_start_lat, order_start_lng, \n",
        "                order_end_lat, order_end_lng, \n",
        "                vehicle_type, city_zones_df, order_time_unix\n",
        "            )\n",
        "\n",
        "            total_road_distance_with_traffic = courier_to_order_dist_with_traffic + order_to_delivery_dist_with_traffic\n",
        "\n",
        "            if vehicle_type == 'Bicycle':\n",
        "                speed_kmh = 15\n",
        "            else:\n",
        "                speed_kmh = 30\n",
        "\n",
        "            courier_to_order_time = calculate_delivery_time(courier_to_order_dist_with_traffic, speed_kmh)\n",
        "            order_to_delivery_time = calculate_delivery_time(order_to_delivery_dist_with_traffic, speed_kmh)\n",
        "            total_delivery_time = courier_to_order_time + order_to_delivery_time\n",
        "\n",
        "            # Calculate the environmental impact using the non-traffic road distance\n",
        "            total_environmental_impact = calculate_environmental_impact(\n",
        "                total_road_distance_no_traffic, co2_emissions_per_km\n",
        "            )\n",
        "\n",
        "            # Track the fastest courier\n",
        "            if total_delivery_time < min_total_time:\n",
        "                min_total_time = total_delivery_time\n",
        "                fastest_courier = courier\n",
        "\n",
        "            # Track the fastest bicycle courier\n",
        "            if vehicle_type == 'Bicycle' and total_delivery_time < min_bicycle_time:\n",
        "                min_bicycle_time = total_delivery_time\n",
        "                fastest_bicycle_courier = courier\n",
        "\n",
        "            # Track the least environmentally impactful courier\n",
        "            if vehicle_type != 'Bicycle' and total_environmental_impact < min_environmental_impact_value:\n",
        "                min_environmental_impact_time = total_delivery_time\n",
        "                least_environmental_impact_courier = courier\n",
        "                min_environmental_impact_value = total_environmental_impact\n",
        "\n",
        "        # Step 2: Start with the fastest courier\n",
        "        chosen_courier = fastest_courier\n",
        "\n",
        "        # Step 3: Now evaluate other couriers based on predefined conditions\n",
        "        # Select bicycle if within 6 minutes of the fastest\n",
        "        if fastest_bicycle_courier is not None and min_bicycle_time <= min_total_time + BICYCLE_TIME_THRESHOLD:\n",
        "            chosen_courier = fastest_bicycle_courier\n",
        "\n",
        "        # Select environmentally friendly courier if within 3 minutes of the fastest\n",
        "        elif least_environmental_impact_courier is not None and min_environmental_impact_time <= min_total_time + ENVIRONMENTAL_TIME_THRESHOLD:\n",
        "            chosen_courier = least_environmental_impact_courier\n",
        "\n",
        "        # Recalculate final road distances, delivery time, and environmental impact\n",
        "        if chosen_courier is not None:\n",
        "            final_courier_to_order_dist_no_traffic = haversine_distance(\n",
        "                chosen_courier['courier_lat'], chosen_courier['courier_lng'],\n",
        "                order['order_start_lat'], order['order_start_lng']\n",
        "            )\n",
        "            final_order_to_delivery_dist_no_traffic = haversine_distance(\n",
        "                order['order_start_lat'], order['order_start_lng'],\n",
        "                order['order_end_lat'], order['order_end_lng']\n",
        "            )\n",
        "            total_road_distance_no_traffic = final_courier_to_order_dist_no_traffic + final_order_to_delivery_dist_no_traffic\n",
        "\n",
        "            final_courier_to_order_dist_with_traffic = apply_segment_traffic_factor(\n",
        "                chosen_courier['courier_lat'], chosen_courier['courier_lng'],\n",
        "                order['order_start_lat'], order['order_start_lng'], \n",
        "                chosen_courier['courier_vehicle_type'], city_zones_df, order_time_unix\n",
        "            )\n",
        "            final_order_to_delivery_dist_with_traffic = apply_segment_traffic_factor(\n",
        "                order['order_start_lat'], order['order_start_lng'],\n",
        "                order['order_end_lat'], order['order_end_lng'], \n",
        "                chosen_courier['courier_vehicle_type'], city_zones_df, order_time_unix\n",
        "            )\n",
        "            total_road_distance_with_traffic = final_courier_to_order_dist_with_traffic + final_order_to_delivery_dist_with_traffic\n",
        "\n",
        "            # Environmental impact is already calculated using the non-traffic distance\n",
        "            final_environmental_impact = calculate_environmental_impact(\n",
        "                total_road_distance_no_traffic, chosen_courier['WLTP_CO2_emissions']\n",
        "            )\n",
        "\n",
        "            # Recalculate total delivery time based on the chosen courier\n",
        "            if chosen_courier['courier_vehicle_type'] == 'Bicycle':\n",
        "                speed_kmh = bicycle_speed\n",
        "            else:\n",
        "                speed_kmh = car_speed\n",
        "\n",
        "            courier_to_order_time = calculate_delivery_time(final_courier_to_order_dist_with_traffic, speed_kmh)\n",
        "            order_to_delivery_time = calculate_delivery_time(final_order_to_delivery_dist_with_traffic, speed_kmh)\n",
        "            total_delivery_time = courier_to_order_time + order_to_delivery_time\n",
        "\n",
        "            # Update courier availability ONLY for the chosen courier\n",
        "            order_end_time_unix = order_time_unix + int(total_delivery_time * 3600)\n",
        "            \n",
        "            # Ensure the chosen courier is marked as busy only after final decision\n",
        "            courier_availabilities[chosen_courier['courier_id']] = {\n",
        "                'available_at': order_end_time_unix,\n",
        "                'lat': order['order_end_lat'],\n",
        "                'lng': order['order_end_lng']\n",
        "            }\n",
        "\n",
        "            # Append the result for the chosen courier\n",
        "            results.append({\n",
        "                'order_id': order['order_id'],\n",
        "                'courier_id': chosen_courier['courier_id'],\n",
        "                'total_delivery_time_hours': total_delivery_time,\n",
        "                'courier_available_at_unix': order_end_time_unix,\n",
        "                'road_distance_no_traffic_km': total_road_distance_no_traffic,\n",
        "                'road_distance_with_traffic_km': total_road_distance_with_traffic,\n",
        "                'vehicle_type': chosen_courier['courier_vehicle_type'],\n",
        "                'environmental_impact_kg_CO2': final_environmental_impact,\n",
        "                'order_start_time_unix': order_time_unix,\n",
        "                'order_end_time_unix': order_end_time_unix,\n",
        "                'Order assigned': \"Successfully assigned\"\n",
        "            })\n",
        "\n",
        "    # Memory tracking after processing orders\n",
        "    print_memory_usage(\"After processing orders\")\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Main function to run processes for each day\n",
        "def run_model_with_multiprocessing(order_positions_df, courier_availability, city_zones_df):\n",
        "    days = order_positions_df['platform_order_day'].unique()\n",
        "    pool = mp.Pool(mp.cpu_count())  # Create a pool of workers\n",
        "    results = pool.starmap(process_orders_for_day, [(order_positions_df[order_positions_df['platform_order_day'] == day], courier_availability, city_zones_df) for day in days])\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "\n",
        "    env_friend_results_df = pd.concat(results, ignore_index=True)\n",
        "    return env_friend_results_df\n",
        "\n",
        "# Example usage with multiprocessing\n",
        "env_friend_results_df = run_model_with_multiprocessing(random_order_positions_df, courier_availability, city_zones_df)\n",
        "print(env_friend_results_df.head())\n",
        "\n",
        "# Save the results as CSV\n",
        "#windows_path = '/mnt/c/Users/baris/Downloads/environmentally_friendly_model_results.csv'\n",
        "#results_df.to_csv(windows_path, index=False)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
